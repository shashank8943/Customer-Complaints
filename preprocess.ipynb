{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics Tool and Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yatharthmathur/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('consumer_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = sorted(list( df['product'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bank account or service',\n",
       " 'Consumer Loan',\n",
       " 'Credit card',\n",
       " 'Credit reporting',\n",
       " 'Debt collection',\n",
       " 'Money transfers',\n",
       " 'Mortgage',\n",
       " 'Other financial service',\n",
       " 'Payday loan',\n",
       " 'Prepaid card',\n",
       " 'Student loan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_maker(x):\n",
    "    for i,c in enumerate(unique_labels):\n",
    "        if c == x:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/555957 [00:00<?, ?it/s]/home/yatharthmathur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n",
      " 34%|███▍      | 190116/555957 [03:50<05:47, 1053.38it/s]/home/yatharthmathur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  import sys\n",
      "/home/yatharthmathur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  \n",
      " 62%|██████▏   | 342844/555957 [08:47<03:48, 934.68it/s] "
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "for i in tqdm.tqdm(df['complaint_id']):\n",
    "    if df[df['complaint_id'] == i]['consumer_complaint_narrative'].item() == 'na':\n",
    "        continue\n",
    "    else:\n",
    "        x_data.append(df[df['complaint_id'] == i]['consumer_complaint_narrative'].item())\n",
    "        y_data.append(df[df['complaint_id'] == i]['product'].item())\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "stopword = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,issue in tqdm.tqdm(enumerate(x_data)):\n",
    "    x_data[i] = x_data[i].lower()\n",
    "    x_data[i] = re.sub(r'[^\\w]', ' ', x_data[i])\n",
    "    x_data[i] = word_tokenize(x_data[i])\n",
    "    x_data[i] = [w for w in x_data[i] if w not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(x_data, size=50, window=5, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, issue in tqdm.tqdm(enumerate(x_data)):\n",
    "    n = len(issue)\n",
    "    for j in range(50-n):\n",
    "        x_data[i].append(' ')\n",
    "    if n>50:\n",
    "        x_data[i] = x_data[i][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_data[1280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,issue in tqdm.tqdm(enumerate(x_data)):\n",
    "    for j,word in enumerate(x_data[i]):\n",
    "        if word in model.wv.vocab.keys():\n",
    "            x_data[i][j] = model[word]\n",
    "        else:\n",
    "            x_data[i][j] = [0]*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive= ['card'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('w2v_embedding.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "ct = 0\n",
    "file = 0\n",
    "n = len(x_data)\n",
    "for i in tqdm.tqdm(range(len(x_data))):\n",
    "    out.append((x_data[i],label_maker(y_data[i])))\n",
    "    ct+=1\n",
    "    n-=1\n",
    "    if ct == 10000 or n == 0:\n",
    "        np.save('npy/'+str(file) + '.npy', out, allow_pickle = True)\n",
    "        file+=1\n",
    "        ct = 0\n",
    "        del out[:]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('w2v_embedding.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA, PCA, TruncatedSVD, KernelPCA, IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = IncrementalPCA(n_components=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    x = []\n",
    "    for d,l in tqdm.tqdm(np.load('npy/'+str(i)+'.npy', allow_pickle=True)):\n",
    "        x.append(list(chain.from_iterable(d)))\n",
    "    transformer.partial_fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(transformer, 'PCA.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_ = load('PCA.joblib')\n",
    "print(transformer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(7)):    \n",
    "    out = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    x = np.load('npy/'+str(i)+'.npy', allow_pickle=True)\n",
    "    for d in x:\n",
    "        data.append(list(chain.from_iterable(d[0])))\n",
    "        labels.append(d[1])\n",
    "    data = transformer_.transform(data)\n",
    "    for j in range(len(x)):\n",
    "        out.append((data[j],labels[j]))\n",
    "    np.save('npy-features/'+str(i) + '.npy', out, allow_pickle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
